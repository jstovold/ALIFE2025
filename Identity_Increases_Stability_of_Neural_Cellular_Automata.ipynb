{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHWLoYnnzA5A"
      },
      "source": [
        "# Identity Increases Stability of Neural Cellular Automata\n",
        "### James Stovold\n",
        "### April 2025\n",
        "\n",
        "\n",
        "Code to support ALIFE 2025 paper:\n",
        " > J. Stovold \"Identity Increases Stability of Neural Cellular Automata\"\n",
        "\n",
        "Based on the Colab notebook developed by Mordvintsev et al. for the [\"Growing Neural Cellular Automata\"](http://distill.pub/2020/growing-ca) article. <!--and J. Stovold's Colab notebook for the [\"Neural Cellular Automata can Respond to Signals\"](https://github.com/jstovold/ALIFE2023/blob/master/ExternalSignals.ipynb) article at ALIFE 2023.-->\n",
        "\n",
        "Code and materials are restricted for any and all use prior to publication; post-publication the code and associated materials are available under the Apache 2.0 license\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLJx-g1tUH3m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKMTzVTCx8rY"
      },
      "outputs": [],
      "source": [
        "#@title Imports and Notebook Utilities\n",
        "\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl\n",
        "import glob\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "from scipy.ndimage.interpolation import rotate as scipy_rotate\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "clear_output()\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def imshow(a, fmt='jpeg'):\n",
        "  display(Image(data=imencode(a, fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(len(a))))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w-len(a))%w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = len(a)//w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "def rotate(img, angle=90):\n",
        "  img = scipy_rotate(img, angle=angle)\n",
        "  return img\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename, fps=30.0, **kw):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kw)\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in [np.float32, np.float64]:\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if len(img.shape) == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer:\n",
        "      self.writer.close()\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, *kw):\n",
        "    self.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k5vhWfdy-uu"
      },
      "outputs": [],
      "source": [
        "#@title Cellular Automata Parameters\n",
        "loading_from_file = True\n",
        "\n",
        "OTHER_N  = 12                       # Number of \"empty\" spaces in the genome for the CA to communicate between cells\n",
        "ID_N     = 1                        # Number of ID channels\n",
        "\n",
        "# Total number of CA state channels (+ 4 for RGBA):\n",
        "CHANNEL_N = 4 + OTHER_N + ID_N\n",
        "\n",
        "TARGET_PADDING = 15                 # Number of pixels used to pad the target image border\n",
        "TARGET_SIZE = 30\n",
        "TARGET_PADDED_SIZE = TARGET_SIZE + TARGET_PADDING * 2\n",
        "\n",
        "BATCH_SIZE = 12\n",
        "POOL_SIZE = 1024\n",
        "CELL_FIRE_RATE = 0.5\n",
        "\n",
        "EXPERIMENT_TYPE = \"Regenerating\" #param [\"Growing\", \"Persistent\", \"Regenerating\"]\n",
        "EXPERIMENT_MAP = {\"Growing\":0, \"Persistent\":1, \"Regenerating\":2}\n",
        "EXPERIMENT_N = EXPERIMENT_MAP[EXPERIMENT_TYPE]\n",
        "\n",
        "USE_PATTERN_POOL = [0, 1, 1][EXPERIMENT_N]\n",
        "DAMAGE_N = [0, 0, 3][EXPERIMENT_N]  # Number of patterns to damage in a batch\n",
        "\n",
        "BEHAVIOUR_SWITCH=2000               # at what point do we change the way we present the target images to the network?\n",
        "THRESHOLD = 0.01                    # kill off any NCAs that don't produce anything visible\n",
        "fix_seed  = False                   # for reproducibility\n",
        "\n",
        "CONTROL = 2     # 0: original NCA model (w/17ch); 1: ID NCA model (w/ one ID); 2: full ID NCA model (i.e. non-control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6QHzWHGz2f4"
      },
      "outputs": [],
      "source": [
        "#@title CA Model and Utilities\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "\n",
        "def load_image(url, max_size=TARGET_SIZE, zoom=1):\n",
        "  r = requests.get(url)\n",
        "  img = PIL.Image.open(io.BytesIO(r.content))\n",
        "  img.thumbnail((max_size*zoom, max_size*zoom), PIL.Image.LANCZOS)\n",
        "  img = np.float32(img)/255.0\n",
        "  img[...,:3] *= img[..., 3:]\n",
        "  return img\n",
        "\n",
        "\n",
        "def load_gecko(zoom=1):\n",
        "  url = \"https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u1f98e.png?raw=true\"\n",
        "  return load_image(url, zoom=zoom)\n",
        "\n",
        "\n",
        "def to_rgba(x):\n",
        "  return x[..., :4]\n",
        "\n",
        "def to_rgba_id(x, y=None):\n",
        "  if CONTROL == 0:\n",
        "    return(x[...,:4])\n",
        "  else:\n",
        "    if y is None:\n",
        "      return tf.concat((x[..., :4], x[..., -ID_N:]), axis=-1)\n",
        "    else:\n",
        "      pad = tf.ones(x[...,-ID_N:].shape, tf.float32) * y\n",
        "      return tf.concat((x[..., :4], pad))\n",
        "\n",
        "def to_alpha(x):\n",
        "  return tf.clip_by_value(x[..., 3:4], 0.0, 1.0)\n",
        "\n",
        "def to_rgb(x):\n",
        "  # assume rgb premultiplied by alpha\n",
        "  rgb, a = x[..., :3], to_alpha(x)\n",
        "  return 1.0-a+rgb\n",
        "\n",
        "def get_channels_no_alpha(x, ch=[5,6,7]):\n",
        "  rgb = x[..., ch]\n",
        "  return 1.0-rgb\n",
        "\n",
        "def get_channels(x, ch=[5,6,7]):\n",
        "  rgb, a = x[..., ch], to_alpha(x)\n",
        "  return 1.0-a+rgb\n",
        "\n",
        "def get_living_mask_wide(x, threshold=0.1):\n",
        "  alpha = x[:, :, :, 3:4]\n",
        "  return tf.nn.max_pool2d(alpha, 5, [1, 1, 1, 1], 'SAME') > threshold\n",
        "\n",
        "def get_living_mask_ff(x, threshold = 0.1):\n",
        "  firefly = x[:, :, :, -ENV_N:]\n",
        "  return tf.nn.max_pool2d(firefly, 3, [1, 1, 1, 1], 'SAME') > threshold\n",
        "\n",
        "\n",
        "def get_living_mask_rgb(x, threshold = 0.1):\n",
        "#   alpha = x[:, :, :, 3:4]\n",
        "  pool = tf.nn.max_pool2d(x[None, ...], 3, [1, 1, 1, 1], 'SAME')\n",
        "  return tf.reduce_max(pool, axis=-1) > threshold\n",
        "\n",
        "def get_living_mask(x, threshold = 0.1):\n",
        "  alpha = x[:, :, :, 3:4]\n",
        "  return tf.nn.max_pool2d(alpha, 3, [1, 1, 1, 1], 'SAME') > threshold\n",
        "\n",
        "def get_living(x):\n",
        "  alpha = x[0, :, :, 3:4]\n",
        "  return tf.nn.max_pool2d(alpha, 3, [1, 1, 1, 1], 'SAME') > 0.1\n",
        "\n",
        "def get_living_mask_np(x):\n",
        "  alpha = x[0, :, :, 3:4]\n",
        "  return (tf.nn.max_pool2d(alpha, 3, [1, 1, 1, 1], 'SAME') > 0.1).numpy()\n",
        "\n",
        "def make_seed(size, n=1):\n",
        "  x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
        "  x[:, size//2, size//2, 3:] = 1.0\n",
        "  return x\n",
        "\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def get_stim(jitter=False):\n",
        "  size = TARGET_PADDED_SIZE\n",
        "  stim_x = (size // 2) - (TARGET_SIZE // 10)\n",
        "  stim_y = (size // 2) - (TARGET_SIZE // 10)\n",
        "\n",
        "  if jitter:\n",
        "    rand = tf.random.uniform(shape=(), minval=-1, maxval=1, dtype=tf.int32)\n",
        "    stim_x = stim_x + rand\n",
        "    stim_y = stim_y + rand\n",
        "\n",
        "  return (stim_x, stim_y)\n",
        "\n",
        "class CAModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
        "    super().__init__()\n",
        "    self.channel_n = channel_n\n",
        "    self.fire_rate = fire_rate\n",
        "\n",
        "    self.dmodel = tf.keras.Sequential([\n",
        "          Conv2D(128, 1, activation=tf.nn.relu, name='layer1'),\n",
        "          Conv2D(self.channel_n, 1, activation=None,\n",
        "              kernel_initializer=tf.zeros_initializer, name='layer2'),\n",
        "    ])\n",
        "\n",
        "    self(tf.zeros([1, 3, 3, channel_n]))  # dummy call to build the model\n",
        "\n",
        "  @tf.function\n",
        "  def perceive(self, x, angle=0.0):\n",
        "    identify = np.float32([0, 1, 0])\n",
        "    identify = np.outer(identify, identify)\n",
        "    dx = np.outer([1, 2, 1], [-1, 0, 1]) / 8.0  # Sobel filter\n",
        "    dy = dx.T\n",
        "    c, s = tf.cos(angle), tf.sin(angle)\n",
        "    kernel = tf.stack([identify, c*dx-s*dy, s*dx+c*dy], -1)[:, :, None, :]\n",
        "    kernel = tf.repeat(kernel, self.channel_n, 2)\n",
        "    y = tf.nn.depthwise_conv2d(x, kernel, [1, 1, 1, 1], 'SAME')\n",
        "    return y\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
        "    pre_life_mask = get_living_mask(x)\n",
        "\n",
        "    y = self.perceive(x, angle)\n",
        "    dx = self.dmodel(y) * step_size\n",
        "    if fire_rate is None:\n",
        "      fire_rate = self.fire_rate\n",
        "    update_mask = tf.random.uniform(tf.shape(x[:, :, :, :1])) <= fire_rate\n",
        "    x += dx * tf.cast(update_mask, tf.float32)\n",
        "\n",
        "    post_life_mask = get_living_mask(x)\n",
        "    life_mask = pre_life_mask & post_life_mask\n",
        "    return x * tf.cast(life_mask, tf.float32)\n",
        "\n",
        "\n",
        "CAModel().dmodel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKWp5Cn7z9h_"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmOsEDbQz4Kq"
      },
      "outputs": [],
      "source": [
        "#@title Train Utilities (SamplePool, Model Export, Damage)\n",
        "from google.protobuf.json_format import MessageToDict\n",
        "from tensorflow.python.framework import convert_to_constants\n",
        "\n",
        "class SamplePool:\n",
        "  def __init__(self, *, _parent=None, _parent_idx=None, **slots):\n",
        "    self._parent = _parent\n",
        "    self._parent_idx = _parent_idx\n",
        "    self._slot_names = slots.keys()\n",
        "    self._size = None\n",
        "    for k, v in slots.items():\n",
        "      if self._size is None:\n",
        "        self._size = len(v)\n",
        "      assert self._size == len(v)\n",
        "      setattr(self, k, np.asarray(v))\n",
        "\n",
        "  def sample(self, n):\n",
        "    idx = np.random.choice(self._size, n, False)\n",
        "    batch = {k: getattr(self, k)[idx] for k in self._slot_names}\n",
        "    batch = SamplePool(**batch, _parent=self, _parent_idx=idx)\n",
        "    return batch\n",
        "\n",
        "  def commit(self):\n",
        "    for k in self._slot_names:\n",
        "      getattr(self._parent, k)[self._parent_idx] = getattr(self, k)\n",
        "\n",
        "@tf.function\n",
        "def make_circle_masks(n, h, w):\n",
        "  x = tf.linspace(-1.0, 1.0, w)[None, None, :]\n",
        "  y = tf.linspace(-1.0, 1.0, h)[None, :, None]\n",
        "  center = tf.random.uniform([2, n, 1, 1], -0.5, 0.5)\n",
        "  r = tf.random.uniform([n, 1, 1], 0.1, 0.4)\n",
        "  x, y = (x-center[0])/r, (y-center[1])/r\n",
        "  mask = tf.cast(x*x+y*y < 1.0, tf.float32)\n",
        "  return mask\n",
        "\n",
        "\n",
        "def export_model(ca, base_fn):\n",
        "  ca.save_weights(base_fn)\n",
        "\n",
        "  cf = ca.call.get_concrete_function(\n",
        "      x=tf.TensorSpec([None, None, None, CHANNEL_N]),\n",
        "      fire_rate=tf.constant(0.5),\n",
        "      angle=tf.constant(0.0),\n",
        "      step_size=tf.constant(1.0))\n",
        "  cf = convert_to_constants.convert_variables_to_constants_v2(cf)\n",
        "  graph_def = cf.graph.as_graph_def()\n",
        "  graph_json = MessageToDict(graph_def)\n",
        "  graph_json['versions'] = dict(producer='1.14', minConsumer='1.14')\n",
        "  model_json = {\n",
        "      'format': 'graph-model',\n",
        "      'modelTopology': graph_json,\n",
        "      'weightsManifest': [],\n",
        "  }\n",
        "  with open(base_fn+'.json', 'w') as f:\n",
        "    json.dump(model_json, f)\n",
        "\n",
        "def generate_pool_figures(pool, step_i):\n",
        "  tiled_pool = tile2d(to_rgb(pool.x[:49]))\n",
        "  fade = np.linspace(1.0, 0.0, 72)\n",
        "  ones = np.ones(72)\n",
        "  tiled_pool[:, :72]  += (-tiled_pool[:,  :72] + ones[None, :, None]) * fade[None, :,    None]\n",
        "  tiled_pool[:, -72:] += (-tiled_pool[:, -72:] + ones[None, :, None]) * fade[None, ::-1, None]\n",
        "  tiled_pool[:72, :]  += (-tiled_pool[:72,  :] + ones[:, None, None]) * fade[:,    None, None]\n",
        "  tiled_pool[-72:, :] += (-tiled_pool[-72:, :] + ones[:, None, None]) * fade[::-1, None, None]\n",
        "  imwrite('train_log/%04d_pool.jpg'%step_i, tiled_pool)\n",
        "\n",
        "def visualize_batch(x0, x, y0, step_i):\n",
        "  vis0 = np.hstack(to_rgb(x0).numpy())\n",
        "  vis1 = np.hstack(to_rgb(x).numpy())\n",
        "  vis2 = np.hstack(to_rgb(y0).numpy())\n",
        "  vis3 = np.hstack(get_channels(x0, [16,16,16]).numpy())\n",
        "  vis4 = np.hstack(get_channels(x.numpy(), [16,16,16]).numpy())\n",
        "  vis = np.vstack([vis0, vis1, vis2, vis3, vis4])\n",
        "  imwrite('train_log/batches_%04d.jpg'%step_i, vis)\n",
        "  print('batch (before/after):')\n",
        "  imshow(zoom(vis,2))\n",
        "\n",
        "def plot_loss(loss_log):\n",
        "  pl.figure(figsize=(10, 4))\n",
        "  pl.title('Loss history (log10)')\n",
        "  pl.plot(np.log10(loss_log), '.', alpha=0.1)\n",
        "  pl.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvpPpeytz4Ic"
      },
      "outputs": [],
      "source": [
        "#@title Choose Target Image { vertical-output: true}\n",
        "\n",
        "target_img = load_gecko()\n",
        "imshow(zoom(to_rgba(target_img), 2), fmt='png')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJX7xeugz4GH"
      },
      "outputs": [],
      "source": [
        "#@title Pull the images from github according to genome { vertical-output: true }\n",
        "\n",
        "target_img_1 = load_gecko()\n",
        "h, w = target_img_1.shape[:2]\n",
        "\n",
        "p = (TARGET_PADDED_SIZE - h) // 2\n",
        "padded_img_1 = tf.pad(target_img_1, [[p, p], [p,p], [0,0]])\n",
        "\n",
        "print(padded_img_1.shape)\n",
        "imshow(zoom(to_rgba(padded_img_1),2),fmt='png')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL0ZOsrBz4Dn"
      },
      "outputs": [],
      "source": [
        "#@title Initialize Training { vertical-output: true}\n",
        "\n",
        "# @tf.function\n",
        "def make_seed_env(signal=1.0):\n",
        "  h, w = (TARGET_PADDED_SIZE, TARGET_PADDED_SIZE)\n",
        "  seed = np.zeros([h, w, CHANNEL_N], np.float32)\n",
        "  seed[h//2, w//2, 3:] = 1.0\n",
        "  if CONTROL == 0:\n",
        "    return seed, 0.0\n",
        "  elif CONTROL == 1:\n",
        "    signal = 1.0\n",
        "\n",
        "  seed[h//2, w//2, -ID_N:] = signal\n",
        "  return seed, signal\n",
        "\n",
        "@tf.function\n",
        "def get_target(target_img, signal):\n",
        "  if CONTROL == 0:\n",
        "    return(target_img)\n",
        "  elif CONTROL == 1:\n",
        "    signal = 1.0\n",
        "\n",
        "  pad = tf.ones(target_img[...,0].shape, tf.float32) * tf.cast(signal, tf.float32)\n",
        "\n",
        "  # restrict signal ID to living cells\n",
        "  mask = get_living_mask_rgb(target_img)\n",
        "  pad = pad * tf.cast(mask, tf.float32)\n",
        "\n",
        "  # stick it on the back of the target image:\n",
        "  new_target_img = tf.concat((target_img, pad[0,...,None]), -1)\n",
        "  return(new_target_img)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "h, w = padded_img_1.shape[:2]\n",
        "print(h,w)\n",
        "seed = np.zeros([h, w, CHANNEL_N], np.float32)\n",
        "seed[h//2, w//2, 3:]  = 1.0\n",
        "seed[h//2, w//2, -ID_N:] = 1.0\n",
        "\n",
        "def loss_f(x, y):\n",
        "  return tf.reduce_mean(tf.square(to_rgba_id(x)-to_rgba_id(y)), [-2, -3, -1])\n",
        "\n",
        "ca = CAModel()\n",
        "\n",
        "loss_log = []\n",
        "lr = 2e-3\n",
        "\n",
        "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    [2000], [lr, lr*0.1])\n",
        "trainer = tf.keras.optimizers.Adam(lr_sched)\n",
        "\n",
        "\n",
        "loss0 = loss_f(seed[None,...], get_target(padded_img_1, 0)[None,...]).numpy()\n",
        "\n",
        "pool = SamplePool(x=np.repeat(seed[None, ...], POOL_SIZE, 0),\n",
        "                  y=np.repeat(get_target(padded_img_1,0)[None,...], POOL_SIZE, 0),\n",
        "                  z=np.repeat(1.0, POOL_SIZE,0))\n",
        "\n",
        "!mkdir -p train_log && rm -f train_log/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX1DOxGwz4Ba",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#@title Training Loop {vertical-output: true}\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  iter_n = tf.random.uniform([], 64, 200, tf.int32)\n",
        "  with tf.GradientTape() as g:\n",
        "    for i in tf.range(iter_n):\n",
        "      x = ca(x)\n",
        "    loss = tf.reduce_mean(loss_f(x, y))\n",
        "  grads = g.gradient(loss, ca.weights)\n",
        "  grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
        "  trainer.apply_gradients(zip(grads, ca.weights))\n",
        "  return x, loss\n",
        "\n",
        "if fix_seed:\n",
        "  tf.random.set_seed(1)\n",
        "\n",
        "if not loading_from_file:\n",
        "  tic = datetime.datetime.now()\n",
        "\n",
        "  start_i = 6\n",
        "  end_i = 9\n",
        "  num_seeded = 3\n",
        "  add_noise = False\n",
        "\n",
        "  for i in range(8000+1):\n",
        "\n",
        "    if i == BEHAVIOUR_SWITCH:\n",
        "      # move signal to middling outputs rather than best outputs\n",
        "      # (keep training best outputs to persist)\n",
        "      start_i    = 6\n",
        "      end_i      = 12\n",
        "      num_seeded = 3\n",
        "      add_noise  = False\n",
        "\n",
        "\n",
        "    if USE_PATTERN_POOL:\n",
        "      batch = pool.sample(BATCH_SIZE)\n",
        "      x0 = batch.x\n",
        "      y0 = batch.y\n",
        "      z0 = batch.z\n",
        "\n",
        "      loss_rank = loss_f(x0, y0).numpy().argsort()[::-1]\n",
        "      x0 = x0[loss_rank]\n",
        "      y0 = y0[loss_rank]\n",
        "      z0 = z0[loss_rank]\n",
        "\n",
        "      for i in range(num_seeded):\n",
        "        x0[i], z0[i] = make_seed_env(np.round(np.random.random() * 2.0) / 2.0)\n",
        "        y0[i] = get_target(padded_img_1, z0[i])\n",
        "\n",
        "      for y in range(start_i, end_i):\n",
        "        # add noise:\n",
        "        if add_noise:\n",
        "          noise = tf.random.uniform(x0[y, ..., :-ID_N].shape, maxval=0.2)\n",
        "          noise = tf.concat((noise, tf.zeros(x0[y,...,-ID_N:].shape)), -1)\n",
        "          x0[y] = x0[y] + noise\n",
        "\n",
        "      for y in range(BATCH_SIZE-DAMAGE_N, BATCH_SIZE):\n",
        "          damage = 1.0-make_circle_masks(1, h, w).numpy()[..., None]\n",
        "          x0[y:] *= damage\n",
        "          if np.sum(to_rgba(x0[y])) < THRESHOLD:\n",
        "            x0[y], z0[y] = make_seed_env(np.round(np.random.random() * 2.0) / 2.0)\n",
        "            y0[y] = get_target(padded_img_1, z0[y])\n",
        "          else:\n",
        "            y0[y,...] = get_target(padded_img_1, z0[y])\n",
        "\n",
        "\n",
        "    else:\n",
        "      seed = make_seed_env()\n",
        "      x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0)\n",
        "\n",
        "    x, loss = train_step(x0, y0)\n",
        "\n",
        "    if USE_PATTERN_POOL:\n",
        "      batch.x[:] = x\n",
        "      batch.y[:] = y0\n",
        "      batch.z[:] = z0\n",
        "      batch.commit()\n",
        "\n",
        "    step_i = len(loss_log)\n",
        "    loss_log.append(loss.numpy())\n",
        "\n",
        "    if step_i%10 == 0:\n",
        "      generate_pool_figures(pool, step_i)\n",
        "    if step_i%100 == 0:\n",
        "      clear_output()\n",
        "      visualize_batch(x0, x, y0, step_i)\n",
        "      print(z0)\n",
        "      plot_loss(loss_log)\n",
        "      export_model(ca, 'train_log/%04d.weights.h5'%step_i)\n",
        "\n",
        "    print('\\r step: %d, log10(loss): %.3f'%(len(loss_log), np.log10(loss)), end='')\n",
        "  toc = datetime.datetime.now()\n",
        "  print(\"\\n\", toc - tic)\n",
        "  loading_from_file = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKRiPMe1rSDb"
      },
      "outputs": [],
      "source": [
        "#@title Save weights to file and download {vertical-output:true}\n",
        "if not loading_from_file:\n",
        "  from google.colab import files\n",
        "  filename = f'model_control_{CONTROL}_rerun.tar.gz'\n",
        "  !tar -zcvf {filename} train_log/\n",
        "  files.download(filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x881btys0PXh"
      },
      "source": [
        "# Figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf-5YlI8sgvj"
      },
      "outputs": [],
      "source": [
        "#@title Load model from file {vertical-output:true}\n",
        "# loading_from_file = True\n",
        "\n",
        "def load_model_from_file():\n",
        "  r = requests.get(f'https://github.com/jstovold/ALIFE2025/raw/refs/heads/master/model_control_{CONTROL}.tar.gz?raw=true')\n",
        "  with open(\"/content/model.tar.gz\", \"wb\") as f:\n",
        "    f.write(r.content)\n",
        "\n",
        "  !rm -rf /content/train_log\n",
        "  !tar -xvf /content/model.tar.gz\n",
        "  !rm /content/model.tar.gz\n",
        "\n",
        "if loading_from_file:\n",
        "  load_model_from_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC3b8uuOUH3o"
      },
      "source": [
        "# Testing multiple organisms in same environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-C-gK5KSHUM"
      },
      "outputs": [],
      "source": [
        "#@title Generate comparison image {vertical-output:true}\n",
        "\n",
        "def generate_comparison_offset_aux(x1,y1, x2,y2, offset1, offset2):\n",
        "  size = TARGET_PADDED_SIZE\n",
        "  comparison_img = np.zeros([size*2, size*3, 4], np.float32)\n",
        "  gecko = load_gecko()\n",
        "  g_size = gecko.shape[0]\n",
        "\n",
        "  top1  = y1 - (g_size//2) + offset1\n",
        "  left1 = x1 - (g_size//2)\n",
        "  top2  = y2 - (g_size//2) + offset2\n",
        "  left2 = x2 - (g_size//2)\n",
        "\n",
        "  comparison_img[top1:top1+g_size, left1:left1+g_size, ...] += gecko\n",
        "  comparison_img[top2:top2+g_size, left2:left2+g_size, ...] += gecko\n",
        "\n",
        "  return(comparison_img)\n",
        "\n",
        "\n",
        "def generate_comparison(distance,offset1=0,offset2=0):\n",
        "  size = TARGET_PADDED_SIZE\n",
        "  comp_img = generate_comparison_offset_aux(int(size*distance), size, size*2, size, offset1, offset2)\n",
        "  return(comp_img)\n",
        "\n",
        "imshow(zoom(to_rgba(generate_comparison(1.9,5,0)), 2), fmt='png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QPuVvf0pVo0"
      },
      "outputs": [],
      "source": [
        "#@title Collect data on errors and bound boxes {vertical-output:true}\n",
        "## N.B. this will take a long time to run (min. 24h)\n",
        "\n",
        "\n",
        "NUM_ORGANISMS       = 1                        # how many to grow\n",
        "model_nums          = [8000] * NUM_ORGANISMS   # set up which model to use\n",
        "distances           = [1.7, 1.75, 1.8, 1.85, 1.9]  # (2.0 -) distance between organisms\n",
        "time_to_seed_second = 10                       # how long to wait between seeds\n",
        "seed_times          = [0, 10, 50, 100, 150, 200, 250]\n",
        "length_of_trial     = 1000                     # how long to run trial for\n",
        "use_drive           = True                     # push output to Google Drive?\n",
        "save_root           = '/content/Output'\n",
        "capture_history     = False\n",
        "offset_vals         = [0,5,10,15]\n",
        "OLD_CONTROL = CONTROL\n",
        "\n",
        "seed1_vals = [0.0,0.5,1.0]\n",
        "seed2_vals = [0.0,0.5,1.0]\n",
        "\n",
        "\n",
        "\n",
        "def calc_bounding_box(x):\n",
        "  # function to calculate the bounding box of the living cells within x\n",
        "  # returns a tuple: (area, width, height, density of fill)\n",
        "  # assumes rank-4 tensor as input: [model, y, x, c]\n",
        "\n",
        "  alpha     = x[...,3]\n",
        "\n",
        "  num_cells = np.count_nonzero(alpha)\n",
        "  cells     = np.nonzero(alpha)\n",
        "\n",
        "  # find top-most, left-most, right-most, and bottom-most cells with a value\n",
        "  top       = np.min(cells[1])\n",
        "  bottom    = np.max(cells[1])\n",
        "  right     = np.min(cells[2])\n",
        "  left      = np.max(cells[2])\n",
        "\n",
        "  # shouldn't need abs, but...\n",
        "  height    = abs(bottom - top) + 1\n",
        "  width     = abs(right - left) + 1\n",
        "\n",
        "  area      = height * width\n",
        "  density   = num_cells / area\n",
        "\n",
        "  return (area, width, height, density, top, left)\n",
        "\n",
        "\n",
        "\n",
        "def rmse(x, y):\n",
        "  return tf.reduce_mean(tf.square(to_rgba(x)-to_rgba(y)), [-2, -3, -1])\n",
        "\n",
        "err = np.zeros((3, len(seed_times), len(distances), len(offset_vals), len(offset_vals), len(seed1_vals), len(seed2_vals), 1000), np.float32)\n",
        "box = np.zeros((3, len(seed_times), len(distances), len(offset_vals), len(offset_vals), len(seed1_vals), len(seed2_vals), 1000, 6), np.float32)\n",
        "total_runs = 3 * len(seed_times) * len(distances) * len(offset_vals) * len(offset_vals) * len(seed1_vals) * len(seed2_vals)\n",
        "run_i = 1\n",
        "\n",
        "\n",
        "model_nums = [8000]\n",
        "\n",
        "time_to_seed_second = 10\n",
        "\n",
        "\n",
        "if use_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  save_root = '/content/drive/MyDrive/Research/NCAs/Identity/Full_Test'\n",
        "\n",
        "for c in range(1,3,1):\n",
        "# if True:\n",
        "  CONTROL = c\n",
        "  load_model_from_file(CONTROL == 1)\n",
        "  root_dir = ''\n",
        "  models = []\n",
        "  for i in model_nums:\n",
        "    ca = CAModel()\n",
        "    ca.load_weights(root_dir + 'train_log/%04d.weights.h5'%i)\n",
        "    models.append(ca)\n",
        "  t_i = -1\n",
        "  for time_to_seed_second in seed_times:\n",
        "    t_i += 1\n",
        "    d = -1\n",
        "    for distance in distances:\n",
        "      d += 1\n",
        "      o1 = -1\n",
        "      for offset in offset_vals:\n",
        "        o1 += 1\n",
        "        o2 = -1\n",
        "        for offset2 in offset_vals:\n",
        "          o2 += 1\n",
        "          comp_img = generate_comparison(distance=distance, offset1=offset, offset2=offset2)\n",
        "          s1 = -1\n",
        "          for seed1 in seed1_vals:\n",
        "            s1 += 1\n",
        "            s2 = -1\n",
        "            for seed2 in seed2_vals:\n",
        "              s2 += 1\n",
        "              x = np.zeros([1, TARGET_PADDED_SIZE*2, TARGET_PADDED_SIZE*3, CHANNEL_N], np.float32)\n",
        "\n",
        "              # seed two organisms:\n",
        "              x[..., TARGET_PADDED_SIZE+offset, int(TARGET_PADDED_SIZE*distance), 3:] = 1.0\n",
        "              x[..., TARGET_PADDED_SIZE+offset, int(TARGET_PADDED_SIZE*distance), -ID_N:] = seed1\n",
        "\n",
        "              out_fn = f'test_boundingbox_gecko_distance_{distance}_control_{CONTROL}_numorg_{NUM_ORGANISMS}_second_{time_to_seed_second}_length_{length_of_trial}_offset1_{offset}_offset2_{offset2}_seed1_{int(seed1*10)}_seed2_{int(seed2*10)}.mp4'\n",
        "\n",
        "\n",
        "              with VideoWriter(out_fn) as vid:\n",
        "                for i in tqdm.trange(1000):\n",
        "                  if i == time_to_seed_second:\n",
        "                    x[..., TARGET_PADDED_SIZE+offset2, TARGET_PADDED_SIZE*2, 3:] = 1.0\n",
        "                    x[..., TARGET_PADDED_SIZE+offset2, TARGET_PADDED_SIZE*2, -ID_N:] = seed2\n",
        "\n",
        "\n",
        "                  bounds = calc_bounding_box(x) #  (area, width, height, density, top, left)\n",
        "                  box[c,t_i,d,o1,o2,s1,s2,i,:] = bounds\n",
        "                  err[c,t_i,d,o1,o2,s1,s2,i]    = rmse(x, comp_img)\n",
        "\n",
        "                  vis = np.hstack(to_rgb(x))\n",
        "                  vis2 = np.hstack(get_channels_no_alpha(x, [16,16,16]))   #]\n",
        "                  vis4 = np.hstack(get_channels(x, [16,16,16]))   #]\n",
        "                  vid1 = np.vstack((vis, vis2, vis4))\n",
        "\n",
        "                  vis_reduced = np.hstack(to_rgb(x[:,20:-20,(-TARGET_PADDED_SIZE*2)+20:-20,:]))\n",
        "\n",
        "                  vid.add(zoom(vid1, 2))\n",
        "                  for ca, xk in zip(models, x):\n",
        "                    xk[:] = ca(xk[None,...])[0]\n",
        "\n",
        "              # save video to {save_root}\n",
        "              !mkdir -p {save_root}/{c}/videos/\n",
        "              !cp {out_fn} {save_root}/{c}/videos/\n",
        "              print(f\"{run_i} / {total_runs}\")\n",
        "              run_i += 1\n",
        "\n",
        "# After everything completes, push bounding box and error values to npy files:\n",
        "np.save('/content/box.npy', box)\n",
        "!cp /content/box.npy {save_root}\n",
        "\n",
        "np.save('/content/err.npy', err)\n",
        "!cp /content/err.npy {save_root}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(box.shape)"
      ],
      "metadata": {
        "id": "415GhiMY-X-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "207W_a2htM6o"
      },
      "outputs": [],
      "source": [
        "\n",
        "NUM_ORGANISMS       = 1                        # how many to grow\n",
        "model_nums          = [8000] * NUM_ORGANISMS   # set up which model to use\n",
        "# distances           = [1.7, 1.75, 1.8, 1.85, 1.9]                      # (2.0 -) distance between organisms\n",
        "distances           = [1.85, 1.9]                      # (2.0 -) distance between organisms\n",
        "time_to_seed_second = 10                       # how long to wait between seeds\n",
        "seed_times          = [10] #0, 50, 100, 150, 200, 250]\n",
        "length_of_trial     = 1000                     # how long to run trial for\n",
        "use_drive           = True\n",
        "save_root           = ''\n",
        "capture_history     = False\n",
        "offset_vals         = [0,5,10,15]\n",
        "OLD_CONTROL = CONTROL\n",
        "run_single_test = True\n",
        "\n",
        "seed1_vals = [0.0,0.5,1.0]\n",
        "seed2_vals = [0.0,0.5,1.0]\n",
        "\n",
        "# seed1_vals = [1.0]\n",
        "# seed2_vals = [1.0]\n",
        "CONTROL = 1\n",
        "import numpy as np\n",
        "save_root = '/content/drive/MyDrive/Research/NCAs/Identity/BoundingBox2_control1'\n",
        "box_control1 = np.load(f\"{save_root}/box_control1.npy\")\n",
        "print(box_control1.shape)\n",
        "\n",
        "def calc_bounding_box(x):\n",
        "  # function to calculate the bounding box of the living cells within x\n",
        "  # returns a tuple: (area, width, height, density of fill)\n",
        "  # assumes rank-4 tensor as input: [model, y, x, c]\n",
        "\n",
        "  alpha     = x[...,3]\n",
        "\n",
        "  num_cells = np.count_nonzero(alpha)\n",
        "  cells     = np.nonzero(alpha)\n",
        "\n",
        "  # find top-most, left-most, right-most, and bottom-most cells with a value\n",
        "  top       = np.min(cells[1])\n",
        "  bottom    = np.max(cells[1])\n",
        "  right     = np.min(cells[2])\n",
        "  left      = np.max(cells[2])\n",
        "\n",
        "  # shouldn't need abs, but...\n",
        "  height    = abs(bottom - top) + 1\n",
        "  width     = abs(right - left) + 1\n",
        "\n",
        "  area      = height * width\n",
        "  density   = num_cells / area\n",
        "\n",
        "  return (area, width, height, density, top, left)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRZan020s1HQ"
      },
      "outputs": [],
      "source": [
        "# yes, perfectly aware this is terrible code, but I don't really care about\n",
        "# speed/memory use, just need to get the data out so I can use R to build the\n",
        "# graphs\n",
        "\n",
        "import pandas as pd\n",
        "box_reduced = box[...,-1,:]    # take only 1000th timestep\n",
        "\n",
        "df = pd.DataFrame(columns = ['control','seed_times','distances', 'offset1', 'offset2', 'seed1', 'seed2', 'area', 'width','height','density', 'top', 'left' ])\n",
        "\n",
        "for c in range(3):\n",
        "  t_i = -1\n",
        "  for t in seed_times:\n",
        "    t_i += 1\n",
        "    d_i = -1\n",
        "    for d in distances:\n",
        "      d_i += 1\n",
        "      o1_i = -1\n",
        "      for o1 in offset_vals:\n",
        "        o1_i += 1\n",
        "        o2_i = -1\n",
        "        for o2 in offset_vals:\n",
        "          o2_i += 1\n",
        "          s1_i = -1\n",
        "          for s1 in seed1_vals:\n",
        "            s1_i += 1\n",
        "            s2_i = -1\n",
        "            for s2 in seed2_vals:\n",
        "              s2_i += 1\n",
        "              this_box = box_reduced[c-1,t_i,d_i,  o1_i, o2_i, s1_i, s2_i,:]\n",
        "              df = pd.concat([df, pd.DataFrame([{'control':c,'seed_times':t,'distances': d, 'offset1': o1, 'offset2': o2, 'seed1':s1, 'seed2':s2, 'area': this_box[0], 'width':this_box[1],'height':this_box[2],'density':this_box[3], 'top':this_box[4], 'left':this_box[5]}])] , ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fAXL3ACuGmg"
      },
      "outputs": [],
      "source": [
        "#@title Push dataframe to CSV file\n",
        "from google.colab import files\n",
        "df_filename = '/content/box.csv'\n",
        "df.to_csv(df_filename)\n",
        "files.download(df_filename)\n",
        "!cp {df_filename} {save_root}/box_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCqEGyeSvE7z"
      },
      "outputs": [],
      "source": [
        "#@title Produce bounding boxes for comparison image as a point of reference\n",
        "import pandas as pd\n",
        "\n",
        "control_bounds = np.zeros((len(distances), len(offset_vals), len(offset_vals),6), np.float32)\n",
        "d_i = -1\n",
        "for distance in distances:\n",
        "  d_i += 1\n",
        "  o1_i = -1\n",
        "  for offset1 in offset_vals:\n",
        "    o1_i += 1\n",
        "    o2_i = -1\n",
        "    for offset2 in offset_vals:\n",
        "      o2_i += 1\n",
        "      img = generate_comparison(distance, offset1, offset2)\n",
        "      temp_bounds = calc_bounding_box(img[None,...])\n",
        "      control_bounds[d_i,o1_i,o2_i, :] = temp_bounds\n",
        "\n",
        "df_control = pd.DataFrame(columns = ['distances', 'offset1', 'offset2', 'area', 'width','height','density', 'top', 'left' ])\n",
        "\n",
        "d_i = -1\n",
        "for d in distances:\n",
        "  d_i += 1\n",
        "  o1_i = -1\n",
        "  for o1 in offset_vals:\n",
        "    o1_i += 1\n",
        "    o2_i = -1\n",
        "    for o2 in offset_vals:\n",
        "      o2_i += 1\n",
        "      this_box = control_bounds[d_i, o1_i, o2_i, :]\n",
        "      df_control = pd.concat([df_control, pd.DataFrame([{'distances': d, 'offset1': o1, 'offset2': o2, 'area': this_box[0], 'width':this_box[1],'height':this_box[2],'density':this_box[3],'top':this_box[4], 'left':this_box[5]}])] , ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnJZbviNwPzu"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "df_filename = '/content/box_control.csv'\n",
        "df_control.to_csv(df_filename)\n",
        "files.download(df_filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
